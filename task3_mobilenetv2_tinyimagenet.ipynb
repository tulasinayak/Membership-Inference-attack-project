{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZQqoSb0J6ZA"
      },
      "source": [
        "### **task3_mobilenetv2_tinyimagenet**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4m_F9ZFn3-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e3ce8a2-84b1-4bf5-9276-9eb4535ec3f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Dfe-lWKowgS"
      },
      "source": [
        "LOADING THE SHADOW.P DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFz75HC9pzDt"
      },
      "outputs": [],
      "source": [
        "#Loading the dataset shadow.p\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/AOML_PROJECT/mobilenetv2/shadow-002.p'\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    shadow_dataset = pickle.load(f)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    shadow_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label) in enumerate(dataloader):\n",
        "    img = img.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-s5ShREB6nVe",
        "outputId": "b915a7fb-05d9-48cb-a6c4-527a5b6f6e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 50000\n"
          ]
        }
      ],
      "source": [
        "print(type(shadow_dataset), len(shadow_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLQNZZNPo9T0"
      },
      "source": [
        "TRAINING THE SHADOW MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRiGBjaw7PYi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyeMLMs4G2mG"
      },
      "outputs": [],
      "source": [
        "#Custom Dataset for the shadow model\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(shadow_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = CustomDataset(train_data, transform=transform)\n",
        "test_dataset = CustomDataset(test_data, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=70, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=70, shuffle=False, num_workers=2)\n",
        "print(\"Length of train_data:\", len(train_data))\n",
        "print(\"Length of test_data:\", len(test_data))"
      ],
      "metadata": {
        "id": "Hs0h_W4L3Qlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjjU6sc1HSJN",
        "outputId": "94543cca-21db-4ca8-a822-6de0c0a4d377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 35.6MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Defining the shadow model\n",
        "shadow_model=models.mobilenet_v2(pretrained=True)\n",
        "shadow_model.classifier[1] = nn.Linear(shadow_model.classifier[1].in_features, 200)  # Tiny ImageNet has 200 classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KrXuZ-mLUctL"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(shadow_model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hy5Qk6HkCe9",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "shadow_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFQLW2Y-kEgC"
      },
      "outputs": [],
      "source": [
        "# Training the Shadow model\n",
        "num_epochs = 15\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    shadow_model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = shadow_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yr5J8P2QkKwb"
      },
      "outputs": [],
      "source": [
        "# Evaluating the shadow model\n",
        "shadow_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = shadow_model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaIIAiuCkMzT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "59a6830d-656c-4ca7-bf7d-143a79166d02"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8bf1b57a-1a78-4eae-8146-a71cf364d049\", \"shadow_model.pth\", 10204468)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(shadow_model, '/content/drive/MyDrive/AOML_PROJECT/shadow_model.pth')\n",
        "\n",
        "# Download the model file\n",
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/AOML_PROJECT/shadow_model.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1NNkyLP7cMQ"
      },
      "outputs": [],
      "source": [
        "shadow_model= torch.load(\"/content/drive/MyDrive/AOML_PROJECT/shadow_model.pth\", map_location=torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "shadow_model.to(device)"
      ],
      "metadata": {
        "id": "q4t7Rs8-CKw4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkfngzMu8Aaq",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "shadow_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onfXkK6l88Oj"
      },
      "source": [
        "GENERATING THE DATASET FOR THE ATTACK MODEL FROM THE SHADOW MODEL (MEMBER AND NON-MEMBER CONFIDENCE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfc8xKet9_cz"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attack_model_dataset = []\n",
        "\n",
        "# Iterate over the test dataset (non-members)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = shadow_model(images)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "            attack_model_dataset.append(probabilities[i].tolist() + [0])  # 0 for non-member"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGOGI2FvADaK"
      },
      "outputs": [],
      "source": [
        "print(attack_model_dataset[0])\n",
        "print(len(attack_model_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lrnooxi_8rx"
      },
      "outputs": [],
      "source": [
        "# Iterate over the train dataset (members)\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = shadow_model(images)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "            attack_model_dataset.append(probabilities[i].tolist() + [1])  # 1 for member\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_qkzYvuBFe6"
      },
      "outputs": [],
      "source": [
        "print(len(attack_model_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6WWtHurb3ST"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/AOML_PROJECT/attack_model_dataset.pkl','wb') as f:\n",
        "  pickle.dump(attack_model_dataset, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0I5ag7-fcdLN"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/MyDrive/AOML_PROJECT/attack_model_dataset.pkl', 'rb') as f:\n",
        "  attack_model_dataset = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(attack_model_dataset[0])"
      ],
      "metadata": {
        "id": "Wa-t0KoCrubu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UXNBIvJBejV"
      },
      "source": [
        "ATTACK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJaclbp9x2i_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert the attack model dataset to tensors\n",
        "attack_model_dataset = torch.tensor(attack_model_dataset, dtype=torch.float32)\n",
        "X = attack_model_dataset[:, :-1]\n",
        "y = attack_model_dataset[:, -1]\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHsf0pLHx2jA"
      },
      "outputs": [],
      "source": [
        "# Defining the attack model\n",
        "class AttackModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(AttackModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6UMEWjax2jA"
      },
      "outputs": [],
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "attack_model = AttackModel(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(attack_model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_EuZ1Z6x2jA"
      },
      "outputs": [],
      "source": [
        "# Training the attack model\n",
        "num_epochs = 65\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "attack_model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    attack_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = attack_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVryP1B6DZ38",
        "outputId": "35518729-a520-466b-fede-4f8002e37802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 84.46%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the attack model\n",
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, labels in test_loader:\n",
        "        tensors, labels = tensors.to(device), labels.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "       # print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCglK-r_Dh7w"
      },
      "outputs": [],
      "source": [
        "# Save the trained attack model\n",
        "torch.save(attack_model.state_dict(), '/content/drive/MyDrive/AOML_PROJECT/attack_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attack_model= torch.load(\"/content/drive/MyDrive/AOML_PROJECT/mobilenetv2/attack_model_final.pth\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "QtTImKAqVg-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/drive/MyDrive/AOML_PROJECT/attack_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hACkkopxNJ9_",
        "outputId": "95c192f0-44fd-4f3d-a5a4-13170c3411c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0bb4b46d-6d8e-422a-ab23-16629965c4d8\", \"attack_model.pth\", 53816)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qupoLvJ8Dpk-"
      },
      "source": [
        "LOADING THE TARGET MODEL AND EVAL.P, GETTING THE CONFIDENCE_SCORE, USING THE CONFIDENCE SCORE TO EVALUVATE THE ATTACK MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRvmPxfWJbgW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/AOML_PROJECT/mobilenetv2_tinyimagenet.pth'\n",
        "# Change the MODEL_PATH to your local model path\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "target_model = models.mobilenet_v2(num_classes=200).to(device)\n",
        "# Change num_classes to 200 when you use the Tiny ImageNet dataset\n",
        "\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "target_model.load_state_dict(state_dict['net'])\n",
        "# Test accuracy\n",
        "acc = state_dict['acc']\n",
        "# Training epoch (start from 0)\n",
        "epoch = state_dict['epoch']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dyi0-9yJbgW"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/AOML_PROJECT/mobilenetv2/eval.p'\n",
        "# Change the DATA_PATH to your local pickle file path\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    eval_dataset = pickle.load(f)\n",
        "sample = next(iter(eval_dataset))\n",
        "print(f'Sample structure: {sample}')\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    eval_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label, membership) in enumerate(dataloader):\n",
        "    img = img.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_dataset[:5])"
      ],
      "metadata": {
        "id": "UdN2o0hcrfz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qbLAtufJbgX"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_scores = []\n",
        "target_model.eval()\n",
        "with torch.no_grad():\n",
        "    for img, label, membership in dataloader:\n",
        "        img = img.to(device)\n",
        "        outputs = target_model(img)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        for i in range(len(img)):\n",
        "          confidence_scores.append(probabilities[i].tolist()+[membership[i]])\n"
      ],
      "metadata": {
        "id": "fgDCpqEjGJOQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confidence_scores[0])"
      ],
      "metadata": {
        "id": "aTiDdIQ6kVAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetConf(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx][:-1]\n",
        "        label = self.data[idx][-1].item()\n",
        "        return torch.tensor(tensor), label"
      ],
      "metadata": {
        "id": "6nzWNCOYmxyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liDy7tIxF4jQ"
      },
      "outputs": [],
      "source": [
        "confidence_file_path = '/content/drive/MyDrive/AOML_PROJECT/confidence_score.pkl'\n",
        "with open(confidence_file_path, 'wb') as f:\n",
        "    pickle.dump(confidence_scores, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/AOML_PROJECT/confidence_score.pkl', 'rb') as f:\n",
        "  confidence_scores = pickle.load(f)"
      ],
      "metadata": {
        "id": "IF4cr4xbWkjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_Score=CustomDatasetConf(confidence_scores)"
      ],
      "metadata": {
        "id": "xzo9W4xxTu7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(conf_Score))"
      ],
      "metadata": {
        "id": "38uWJn1UoawW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrncIrEajcOw"
      },
      "outputs": [],
      "source": [
        "confidence_scores_loader = DataLoader(conf_Score, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UALYhLDkddA",
        "outputId": "dca6d835-0ef6-40b0-935a-427386a977c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 82.0%\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the attack model using thhe confidence score generated by the target model and eval.p\n",
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, label in confidence_scores_loader:\n",
        "        tensors, label = tensors.to(device), label.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += tensors.size(0)\n",
        "        correct += (predicted==label).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GENERATING THE RESULT OF THE TEST.P"
      ],
      "metadata": {
        "id": "CH589gSrekNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/AOML_PROJECT/mobilenetv2/test.p'\n",
        "# Change the DATA_PATH to your local pickle file path\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    testp_dataset = pickle.load(f)\n",
        "\n",
        "sample = next(iter(testp_dataset))\n",
        "print(f'Sample structure: {sample}')\n",
        "testp_dataloader = torch.utils.data.DataLoader(\n",
        "    testp_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label) in enumerate(testp_dataloader):\n",
        "    img = img.to(device)"
      ],
      "metadata": {
        "id": "CWYnVFj1ewQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(testp_dataset[0][0].size())"
      ],
      "metadata": {
        "id": "awpa13tsrVcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_confidence_scores = []\n",
        "target_model.eval()\n",
        "with torch.no_grad():\n",
        "    for img,label in testp_dataloader:\n",
        "        img = img.to(device)\n",
        "        outputs = target_model(img)\n",
        "       # print(outputs.shape)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        for i in range(len(img)):\n",
        "          test_confidence_scores.append(probabilities[i].tolist())\n",
        "print(test_confidence_scores[0])"
      ],
      "metadata": {
        "id": "JuhXREPKfWRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_confidence_scores[0]))"
      ],
      "metadata": {
        "id": "34mcjbA3qt2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetConft(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx]\n",
        "\n",
        "        return torch.tensor(tensor)"
      ],
      "metadata": {
        "id": "9XVNyT2xrGe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_conf_score=CustomDatasetConft(test_confidence_scores)"
      ],
      "metadata": {
        "id": "KvOhzKQ9qT2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_conf_score[0])\n",
        "print(len(test_conf_score[0]))"
      ],
      "metadata": {
        "id": "t0AwTexnsUT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the attack model using test.p\n",
        "attack_model.eval()\n",
        "Final_result=[]\n",
        "with torch.no_grad():\n",
        "    for tensors in test_conf_score:\n",
        "        tensors = tensors.to(device)\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        Final_result.append(predicted.item())"
      ],
      "metadata": {
        "id": "5jxXRB0Fr2kR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT"
      ],
      "metadata": {
        "id": "9lUmtm2p5AZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted = np.array(Final_result)"
      ],
      "metadata": {
        "id": "idU8YQPT1PmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3fUSuW91inw",
        "outputId": "a15b053f-8c15-4e9a-d92e-a6e1fe1b721e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 1. ... 1. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('task3_mobilenetv2_tinyimagenet.npy', predicted)"
      ],
      "metadata": {
        "id": "KD13qoxP1kbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('task3_mobilenetv2_tinyimagenet.npy')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EjEXtbad2cMo",
        "outputId": "cddd9cfa-1749-42d5-88c8-fabd92cd5f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d3701445-4057-4e29-99b1-6b38a5261c52\", \"task3_mobilenetv2_tinyimagenet.npy\", 160128)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}