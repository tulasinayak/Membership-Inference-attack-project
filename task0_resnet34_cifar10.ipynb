{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "052yaJn2-u4i",
        "outputId": "872059d2-96c8-4b36-f6d7-56305c14dd99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading shadow.p and target_model"
      ],
      "metadata": {
        "id": "8FcfkrpoVTg6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vbTUU9Pq-i-0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/pickle/cifar10/resnet34/shadow.p\"\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label) in enumerate(dataloader):\n",
        "    img = img.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RNU3YbAr-i-1"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "MODEL_PATH = \"/content/drive/MyDrive/models/resnet34_cifar10.pth\"\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "target_model = models.resnet34(num_classes=10).to(device)\n",
        "\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "target_model.load_state_dict(state_dict['net'])\n",
        "acc = state_dict['acc']\n",
        "epoch = state_dict['epoch']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3INLvUw2-i-6"
      },
      "source": [
        "\n",
        "\n",
        "## Shadow model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ciMxY6OL-i-6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XIksnA99-i-7"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hbWYHJQs-i-7"
      },
      "outputs": [],
      "source": [
        "train_data, test_data = train_test_split(dataset, test_size=0.36, random_state=42)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(train_data, transform=transform)\n",
        "test_dataset = CustomDataset(test_data, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
        "val_loader = DataLoader(test_dataset, batch_size=50, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JgQXLPYX-i-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b157b1-176d-4ff5-cdc2-db89d49e64d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 102MB/s]\n"
          ]
        }
      ],
      "source": [
        "model = models.resnet34(pretrained=True) #import resnet34\n",
        "\n",
        "\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 10) #change to match our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "umz8dO8i-i-7"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZucJF6ze-i-7",
        "outputId": "d4308648-1e1a-4a12-d71f-eab60ddf3bb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "384\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXJ6gR77-i-7",
        "outputId": "f7f4b7ec-2c36-459c-cf34-21f7f390407e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.1940001441786687\n",
            "Epoch 2, Loss: 0.6700422165837759\n",
            "Epoch 3, Loss: 0.45855264257018763\n",
            "Epoch 4, Loss: 0.3207520821209376\n",
            "Epoch 5, Loss: 0.23335544646639997\n",
            "Epoch 6, Loss: 0.16996072488836944\n",
            "Epoch 7, Loss: 0.13757685246916176\n",
            "Epoch 8, Loss: 0.1175926087720048\n",
            "Epoch 9, Loss: 0.10179240263823885\n",
            "Epoch 10, Loss: 0.08125136534605797\n",
            "Epoch 11, Loss: 0.08270862133213086\n",
            "Epoch 12, Loss: 0.06074082056632809\n",
            "Epoch 13, Loss: 0.06570242371223382\n",
            "Epoch 14, Loss: 0.057361919908241056\n",
            "Epoch 15, Loss: 0.054369070595081816\n",
            "Epoch 16, Loss: 0.05538081398056723\n",
            "Epoch 17, Loss: 0.04442037922126474\n",
            "Epoch 18, Loss: 0.04710636304783596\n",
            "Epoch 19, Loss: 0.04710769882967725\n",
            "Epoch 20, Loss: 0.04594998536807301\n",
            "Epoch 21, Loss: 0.04023627380972054\n",
            "Epoch 22, Loss: 0.038240819712427765\n",
            "Epoch 23, Loss: 0.03633620104240739\n",
            "Epoch 24, Loss: 0.03809963184274542\n",
            "Epoch 25, Loss: 0.038942404278107766\n",
            "Epoch 26, Loss: 0.02772755377751916\n",
            "Epoch 27, Loss: 0.03272996057406393\n",
            "Epoch 28, Loss: 0.03032018743435098\n",
            "Epoch 29, Loss: 0.026719267678648368\n",
            "Epoch 30, Loss: 0.02190248518892683\n",
            "Epoch 31, Loss: 0.025106885916329702\n",
            "Epoch 32, Loss: 0.029733522598386724\n",
            "Epoch 33, Loss: 0.02800953534188011\n",
            "Epoch 34, Loss: 0.018889029244386773\n",
            "Epoch 35, Loss: 0.01812641208956241\n",
            "Epoch 36, Loss: 0.027250061202266807\n",
            "Epoch 37, Loss: 0.025978318255776383\n",
            "Epoch 38, Loss: 0.019725638757980352\n",
            "Epoch 39, Loss: 0.01991224713075705\n",
            "Epoch 40, Loss: 0.017270097902629306\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "num_epochs = 40\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")\n",
        "\n",
        "print(\"Finished Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52uXTshO-i-8",
        "outputId": "d17acab6-0a00-49ab-e82f-17433978605b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 80.71296296296296%\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XYxW4Ujb-i-8"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), 'most_recent_shadow.pth') #saving the model weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating dataset to train attack model"
      ],
      "metadata": {
        "id": "DwnhdEzFX-Vz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyHWYlSR-i-8",
        "outputId": "d8743763-4d89-4f74-8084-460e5aef321b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "attack_model_dataset = []\n",
        "print(len(attack_model_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uyUdG0pX-i-8"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "attack_model_dataset = []\n",
        "cnt = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "          attack_model_dataset.append(probabilities[i].tolist()+[0]) #0 because it is test data, non-member for the shadow model\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joMeul6Q-i-8",
        "outputId": "6608f777-3d10-484d-eb6f-8d6ccb664b9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10800\n"
          ]
        }
      ],
      "source": [
        "print(len(attack_model_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "aEB10VFu-i-9"
      },
      "outputs": [],
      "source": [
        "cnt = 0\n",
        "with torch.no_grad():\n",
        "    cnt=0\n",
        "    for images, labels in train_loader:\n",
        "        cnt+=1\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "          attack_model_dataset.append(probabilities[i].tolist()+[1]) #1 because it is train data, member for the shadow model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRrKVNFj-i-9",
        "outputId": "1624cadc-5c32-404f-a1f1-1f0ce1aba377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30000\n"
          ]
        }
      ],
      "source": [
        "print(len(attack_model_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attack Model"
      ],
      "metadata": {
        "id": "nuRSFoUjYE7y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u6CjU5vW-i-9"
      },
      "outputs": [],
      "source": [
        "class CustomAttackDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx][:-1]\n",
        "        label = self.data[idx][-1]\n",
        "        return torch.tensor(tensor), label\n",
        "\n",
        "\n",
        "attack_dataset = CustomAttackDataset(attack_model_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yTgdjAJ_-i-9"
      },
      "outputs": [],
      "source": [
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 32)\n",
        "        self.fc5 = nn.Linear(32, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "attack_model = BinaryClassifier()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR2LKpPX-i-9",
        "outputId": "675a9664-d3cc-47e5-b874-415eb407640f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: 28500\n",
            "test shape: 1500\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "train_size = int(0.95 * len(attack_dataset))\n",
        "test_size = len(attack_dataset) - train_size\n",
        "train_attack_dataset, test_attack_dataset = random_split(attack_dataset, [train_size, test_size])\n",
        "\n",
        "train_attack_loader = DataLoader(train_attack_dataset, batch_size=16, shuffle=True)\n",
        "test_attack_loader = DataLoader(test_attack_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "print(\"train shape:\", len(train_attack_dataset))\n",
        "\n",
        "print(\"test shape:\", len(test_attack_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgpzPiAY-i-9",
        "outputId": "1ba1f648-c12a-44ed-d6b9-b5c68b80d1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([2.0825e-03, 8.1222e-06, 1.3062e-04, 1.9248e-05, 1.2406e-07, 9.9753e-01,\n",
            "        1.7637e-07, 1.7143e-04, 5.0896e-05, 9.0517e-06]), 1)\n"
          ]
        }
      ],
      "source": [
        "print(train_attack_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRSSeBVp-i--",
        "outputId": "40623a95-f568-4ad6-8165-86dd13ca45e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.649994349539882\n",
            "Epoch 2, Loss: 0.6326193025484096\n",
            "Epoch 3, Loss: 0.5964781638113604\n",
            "Epoch 4, Loss: 0.5847617559695217\n",
            "Epoch 5, Loss: 0.5807793198276717\n",
            "Epoch 6, Loss: 0.5791314361004449\n",
            "Epoch 7, Loss: 0.5784545913756763\n",
            "Epoch 8, Loss: 0.5783849672469761\n",
            "Epoch 9, Loss: 0.5774542195461146\n",
            "Epoch 10, Loss: 0.5769557226470157\n",
            "Epoch 11, Loss: 0.5761402792032854\n",
            "Epoch 12, Loss: 0.5758175578148143\n",
            "Epoch 13, Loss: 0.5752691899485861\n",
            "Epoch 14, Loss: 0.5754783342014392\n",
            "Epoch 15, Loss: 0.5740189875918206\n",
            "Epoch 16, Loss: 0.5744686200127724\n",
            "Epoch 17, Loss: 0.5734735580138218\n",
            "Epoch 18, Loss: 0.5729668593634125\n",
            "Epoch 19, Loss: 0.5729746277685519\n",
            "Epoch 20, Loss: 0.5722451736830702\n",
            "Epoch 21, Loss: 0.5718330847461082\n",
            "Epoch 22, Loss: 0.5713764180906962\n",
            "Epoch 23, Loss: 0.5714927615073125\n",
            "Epoch 24, Loss: 0.570631872958741\n",
            "Epoch 25, Loss: 0.5701288083018411\n",
            "Epoch 26, Loss: 0.5700926613292576\n",
            "Epoch 27, Loss: 0.569750752095154\n",
            "Epoch 28, Loss: 0.5688261394080624\n",
            "Epoch 29, Loss: 0.5691222854033865\n",
            "Epoch 30, Loss: 0.5683374122102921\n",
            "Epoch 31, Loss: 0.5678102231754866\n",
            "Epoch 32, Loss: 0.5678562781325093\n",
            "Epoch 33, Loss: 0.5674872764801203\n",
            "Epoch 34, Loss: 0.567218159117415\n",
            "Epoch 35, Loss: 0.5666633307866911\n",
            "Epoch 36, Loss: 0.566525831885477\n",
            "Epoch 37, Loss: 0.5669850027554498\n",
            "Epoch 38, Loss: 0.5663870456727801\n",
            "Epoch 39, Loss: 0.5658467627150309\n",
            "Epoch 40, Loss: 0.5649685887776641\n",
            "Epoch 41, Loss: 0.5654100740430866\n",
            "Epoch 42, Loss: 0.5644401677295683\n",
            "Epoch 43, Loss: 0.5645561665380175\n",
            "Epoch 44, Loss: 0.5646084130863951\n",
            "Epoch 45, Loss: 0.5638435491006383\n",
            "Epoch 46, Loss: 0.5636481146686674\n",
            "Epoch 47, Loss: 0.5636675442108\n",
            "Epoch 48, Loss: 0.5634704596466489\n",
            "Epoch 49, Loss: 0.5628693478827926\n",
            "Epoch 50, Loss: 0.5624923028143836\n",
            "Epoch 51, Loss: 0.5631029731296129\n",
            "Epoch 52, Loss: 0.5627702736660554\n",
            "Epoch 53, Loss: 0.561988734193857\n",
            "Epoch 54, Loss: 0.5616919979051709\n",
            "Epoch 55, Loss: 0.5620797289207193\n",
            "Epoch 56, Loss: 0.5616112267629867\n",
            "Epoch 57, Loss: 0.5615269337706561\n",
            "Epoch 58, Loss: 0.5618004112699886\n",
            "Epoch 59, Loss: 0.5610485725464377\n",
            "Epoch 60, Loss: 0.5607458285979016\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(attack_model.parameters(), lr=0.0001)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "attack_model.to(device)\n",
        "\n",
        "num_epochs = 60\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    attack_model.train()\n",
        "    running_loss = 0.0\n",
        "    for tensors, labels in train_attack_loader:\n",
        "        tensors, labels = tensors.to(device), labels.to(device).float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_attack_loader)}\")\n",
        "\n",
        "print(\"Finished Training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61Vk9wsS-i--",
        "outputId": "a7ff88c8-413e-42af-ee92-83a8d6ea9618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 72.86666666666666%\n"
          ]
        }
      ],
      "source": [
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, labels in test_attack_loader:\n",
        "        tensors, labels = tensors.to(device), labels.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the eval.p file and find accuracy"
      ],
      "metadata": {
        "id": "ZE5vHIP7Ybdp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Uy2n450N-i--"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/pickle/cifar10/resnet34/eval.p\"\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    eval_dataset = pickle.load(f)\n",
        "\n",
        "eval_dataloader = torch.utils.data.DataLoader(\n",
        "    eval_dataset, batch_size=64, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTe98bdu-i--",
        "outputId": "3aeecf44-d944-4a7a-f0fe-0a6e6e12662b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ],
      "source": [
        "print(len(eval_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_XorQlcI-i-_",
        "outputId": "e25547be-c0ca-4af5-9ebf-5722bcdc2a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of target model : 85.5\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "target_model.eval()\n",
        "attack_model_eval_dataset = []\n",
        "total=0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels, membership in eval_dataloader:\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = target_model(images)\n",
        "        #print(outputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        for i in range(len(images)):\n",
        "          attack_model_eval_dataset.append(probabilities[i].tolist()+[membership[i]])\n",
        "\n",
        "print(\"Accuracy of target model :\", 100*(correct/total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1MZh_2t5-i-_"
      },
      "outputs": [],
      "source": [
        "attack_eval_dataset = CustomAttackDataset(attack_model_eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "X2iRPty4-i-_"
      },
      "outputs": [],
      "source": [
        "attack_eval_loader = DataLoader(attack_eval_dataset, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw5AW5zL-i-_",
        "outputId": "35ca1e3a-5b05-4b26-b5e6-fbe1bee857c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 68.0%\n"
          ]
        }
      ],
      "source": [
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, labels in attack_eval_loader:\n",
        "        tensors, labels = tensors.to(device), labels.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load test.p file and generate predictions"
      ],
      "metadata": {
        "id": "OxdNbbVOYq7R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Q51CWEsW-i_E"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/pickle/cifar10/resnet34/test.p\"\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    test_dataset = pickle.load(f)\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "target_model.eval()\n",
        "final_test_dataset = []\n",
        "total=0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    cnt=0\n",
        "    for images, labels in test_dataloader:\n",
        "\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = target_model(images)\n",
        "        #print(outputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        for i in range(len(images)):\n",
        "          final_test_dataset.append(probabilities[i].tolist())"
      ],
      "metadata": {
        "id": "1gxKqMXH5RSG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_test_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWfY9kCnNMmb",
        "outputId": "fac3a10d-6a3b-4f81-f4a1-bb626f042388"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.531347414944321e-05, 0.00011613118840614334, 0.00021471142827067524, 0.0001690014760242775, 0.00030225186492316425, 0.0006084183696657419, 0.9982144832611084, 8.302015339722857e-05, 6.725761340931058e-05, 0.00016943008813541383]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class FinalTestDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx]\n",
        "        return torch.tensor(tensor, dtype=torch.float32)\n",
        "\n",
        "final_test_dataset = FinalTestDataset(final_test_dataset)\n",
        "final_test_loader = torch.utils.data.DataLoader(final_test_dataset, batch_size=16, shuffle=False)\n"
      ],
      "metadata": {
        "id": "r8n3NTl85bZw"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_test_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vNUrEShOvAv",
        "outputId": "bf073df4-e4c6-491d-e68f-62f831c91559"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.5313e-05, 1.1613e-04, 2.1471e-04, 1.6900e-04, 3.0225e-04, 6.0842e-04,\n",
            "        9.9821e-01, 8.3020e-05, 6.7258e-05, 1.6943e-04])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xaCaNZKHI3HE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save predicted values"
      ],
      "metadata": {
        "id": "C8rxL1cpZE7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "attack_model.eval()\n",
        "predicted_values = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for prob in final_test_loader:\n",
        "        prob = prob.to(device)\n",
        "        outputs = attack_model(prob).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        predicted_values.extend(predicted.cpu().numpy())\n",
        "\n",
        "predicted_array = np.array(predicted_values)\n",
        "print(predicted_array)\n",
        "np.save('predicted_values.npy', predicted_array)\n"
      ],
      "metadata": {
        "id": "_ru-Igrd5hbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23aa9d93-c4ad-4db2-c85b-02d79ca85890"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. ... 0. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_array[:100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvwIxq5fPYwT",
        "outputId": "450c9352-70b1-4443-f930-a4cc9e3a4e3f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
            " 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 0. 1. 0. 1.]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}