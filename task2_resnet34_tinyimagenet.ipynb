{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EvB-BMFBMKs",
        "outputId": "77cd03be-8e55-44f5-e1ae-a8b8d7ca560f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1fjkLbDBD0m"
      },
      "outputs": [],
      "source": [
        "#Loading the dataset shadow.p\n",
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/AMLM/pickle/tinyimagenet/resnet34/shadow.p\"\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label) in enumerate(dataloader):\n",
        "    img = img.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(dataset), len(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaepGxFhFxp2",
        "outputId": "5ac01727-de05-4e5a-cb70-a9fc3ce74030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'> 50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "YAxKReT4ItWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    shadow_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "q4pP0_wrIvye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom Dataset for the shadow model\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.data[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "train_data, test_data = train_test_split(shadow_dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "train_dataset = CustomDataset(train_data, transform=transform)\n",
        "test_dataset = CustomDataset(test_data, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=False, num_workers=2)\n",
        "print(\"Length of train_data:\", len(train_data))\n",
        "print(\"Length of test_data:\", len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJioL71OI2U_",
        "outputId": "4accfc54-96fd-4fa8-ee55-635670b1283c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of train_data: 40000\n",
            "Length of test_data: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models"
      ],
      "metadata": {
        "id": "x5wiUhpxNVF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(set([label for _, label in shadow_dataset]))\n",
        "resnet34 = models.resnet34(pretrained=True)\n",
        "resnet34.fc = nn.Linear(resnet34.fc.in_features, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymq3tkhhMDhD",
        "outputId": "96406dfa-126d-4481-ab26-bd2a932422fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 162MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet34.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuy00e_CMGUN",
        "outputId": "66aba538-5d15-451d-c752-5f3411d59b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(resnet34.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "id": "hOL4n5q4PPQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the shadow model\n",
        "num_epochs = 18\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    resnet34.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = resnet34(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "2E4XawGOMR42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the shadow model\n",
        "resnet34.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet34(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "id": "3s4f4cjqN2FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6PMHGifbsTf",
        "outputId": "9414d5f6-ab6b-422c-f2f1-868b5c3e560e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "torch.save(resnet34, '/content/drive/MyDrive/AMLM/pickle/shadow_model.pth')"
      ],
      "metadata": {
        "id": "DRgkn5pTQLMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_model= torch.load(\"/content/drive/MyDrive/AMLM/pickle/shadow_model.pth\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "54NKnSwd4vfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the shadow model\n",
        "shadow_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet34(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evOhUCzn6aym",
        "outputId": "d2d64fb8-a282-4110-91ae-45461910475d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 62.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "psd12lTL5ENK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shadow_model.to(device)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmhsqd7L49Fw",
        "outputId": "2ccd94ba-7f72-41ad-b6ca-204536a61e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (3): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (4): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (5): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (2): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=200, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating the dataset for the attack model from the shadow model (member and non-member)**"
      ],
      "metadata": {
        "id": "IXOc0ay0Ohon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "attack_model_dataset = []\n",
        "\n",
        "# Iterate over the test dataset (non-members)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet34(images)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "            attack_model_dataset.append(probabilities[i].tolist() + [0])  # 0 for non-member"
      ],
      "metadata": {
        "id": "G2Dm3zebeAwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(attack_model_dataset[0])\n",
        "print(len(attack_model_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH1grzJueFdy",
        "outputId": "9c191e54-0e9f-46cd-d946-d344c10680a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5.845411124028033e-07, 5.587342911894666e-06, 2.217735982412705e-06, 3.556857700459659e-05, 2.1925433202341083e-07, 4.969369342688879e-07, 7.181667882605325e-08, 1.5273000826709904e-05, 1.0379835657658987e-06, 5.557891995522368e-07, 2.8046534339409845e-07, 1.4812869153502106e-07, 1.583101294500011e-08, 1.1031273672301722e-08, 6.76423184131636e-08, 1.0715821190387942e-05, 0.00016664514259900898, 2.574406607891433e-07, 1.508455170551315e-06, 5.009425763091713e-08, 2.9444516158605438e-08, 9.138507834904885e-07, 2.1317507759022192e-08, 1.8596094264466956e-07, 8.054144018387888e-07, 2.4059903580564423e-07, 9.301848876930308e-06, 4.79447521684051e-07, 6.946162756094054e-08, 3.111842943326337e-07, 1.01738510238647e-06, 3.68215467005939e-08, 8.51351899200381e-07, 2.500266873539658e-07, 9.376564236163176e-08, 3.518029600968475e-08, 0.9994786381721497, 3.2986140467983205e-06, 9.886385669233277e-06, 4.380259269964881e-06, 2.1378023973284144e-07, 4.321781943872338e-06, 1.0792584959062879e-07, 1.3773715181741863e-06, 7.709130613875459e-07, 3.6517621992970817e-06, 1.786449388418987e-07, 3.94350450960701e-07, 9.774537375051295e-07, 8.056948104240291e-07, 1.242225607711589e-06, 4.2604412442415196e-07, 8.178084875964942e-09, 5.931189051011643e-08, 7.911204846777764e-08, 7.403480140055763e-08, 2.311962958856384e-07, 1.1124395626893602e-07, 3.070202865274041e-07, 1.355626977783686e-06, 1.3949597921225632e-08, 4.75280863554417e-08, 2.2524248777244793e-07, 3.698865924661732e-08, 1.6206938369123236e-07, 8.186079014649295e-08, 9.839839094638592e-07, 1.107344587580883e-06, 3.1428410238731885e-06, 4.4340421823108045e-07, 2.232703309346107e-06, 1.1839824765047524e-07, 1.3071228011085623e-07, 1.8379671473667258e-07, 8.766251653469226e-07, 8.110720841614238e-07, 4.5688247496400436e-07, 3.5464762504489045e-07, 3.8140191804814094e-07, 3.249554083595285e-07, 1.0562627039689687e-06, 1.5603458791701996e-07, 8.153927311127518e-09, 4.080244480064721e-07, 4.254446039908544e-08, 7.155335168818056e-08, 9.201801276503829e-08, 2.3131728994485456e-06, 3.695912482726271e-07, 3.5195279224353726e-07, 1.1385314024892068e-07, 4.245863181040477e-07, 1.2579555175307178e-07, 3.4043232517433353e-06, 7.26166859976729e-08, 1.433035663467308e-07, 7.825780556913742e-08, 1.277302459357088e-07, 2.0276164036658884e-07, 1.7393941220689157e-07, 1.9345004602655536e-06, 2.44023198092691e-07, 2.197689070726483e-07, 1.0878649163714726e-06, 1.1743249928031219e-07, 4.085315907786935e-08, 6.733187660756812e-07, 7.474094587678337e-08, 8.92832616727901e-08, 6.49034959110395e-08, 7.072579677469548e-08, 8.102078368210641e-07, 5.639760729536647e-07, 1.3675407899427228e-06, 3.928353180526756e-06, 4.2225639163007145e-07, 1.4315153862298757e-07, 9.206898425873078e-07, 1.0214902346206145e-07, 8.346260216285373e-08, 1.747781368521828e-07, 2.161229986086255e-06, 1.9451301795925247e-06, 1.55462966944242e-08, 3.595131090605719e-07, 3.859846344766993e-07, 1.8903923759694408e-08, 1.6994398777114839e-07, 6.365142724007455e-08, 1.954404211801375e-07, 8.201231139537413e-06, 3.027666650723404e-07, 8.692472164284482e-08, 6.455979928432498e-07, 9.498539839114528e-07, 4.129120725337998e-07, 1.5758206473037717e-07, 5.60099181257101e-07, 7.044011596235578e-08, 2.5199033188982867e-05, 6.074947833667466e-08, 6.701189363411686e-07, 1.4182988650190964e-07, 3.3482422168162884e-07, 1.6669297338012257e-06, 9.629313808545703e-07, 2.734935264925298e-07, 1.5347815462973813e-07, 3.3354587003486813e-07, 6.365783065120922e-07, 1.1825515855434787e-07, 1.2285173056625354e-07, 7.503694519073179e-07, 9.141267582890578e-06, 8.864829226240545e-08, 1.3634165725306957e-06, 4.3832496885443106e-05, 7.901342513605414e-08, 8.588023803213218e-08, 2.055428183211916e-07, 2.420097189315129e-05, 5.683178187609883e-06, 4.689230195253913e-07, 5.985343136671872e-07, 3.9468150703214633e-07, 9.625195218632143e-08, 2.870911828267708e-07, 4.14315692864875e-08, 8.835339031065814e-06, 1.386287067361991e-07, 7.41240953061606e-08, 3.746162747120252e-06, 1.6066290982053033e-06, 2.138854711120075e-07, 1.0770987728392356e-06, 6.5018475652323104e-06, 3.01162913274311e-07, 3.749535153474426e-07, 2.6603248670653556e-07, 4.661961611418519e-06, 4.784062070939399e-07, 1.916274641189375e-06, 5.3381747022740456e-08, 2.09345375878911e-06, 1.8725125983110047e-06, 8.318418622366153e-06, 7.760233984299703e-07, 5.981611934657849e-07, 3.4266709008079488e-06, 4.291197456041118e-06, 2.985803959631994e-08, 2.5523121394144255e-07, 5.067656729806913e-07, 2.8034818910782633e-07, 3.7623368598360685e-07, 5.107646074975492e-07, 2.7478765218802437e-07, 5.55327233087155e-07, 7.001857227351138e-08, 6.988095719862031e-06, 0]\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the train dataset (members)\n",
        "with torch.no_grad():\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = resnet34(images)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "        for i in range(len(images)):\n",
        "            attack_model_dataset.append(probabilities[i].tolist() + [1])  # 1 for member\n"
      ],
      "metadata": {
        "id": "TnH-O8IpeG-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(attack_model_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uf8wEyY_eIX9",
        "outputId": "634ca3c9-6ec5-4ca0-a3c3-52b418549381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the dataset to a file\n",
        "with open('/content/drive/MyDrive/AMLM/pickle/attack_model_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(attack_model_dataset, f)"
      ],
      "metadata": {
        "id": "nAYkRQ7a7Fn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "RujGV5qgeKXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/AMLM/pickle/attack_model_dataset.pkl', 'rb') as f:\n",
        "  attack_model_dataset = pickle.load(f)"
      ],
      "metadata": {
        "id": "5EFX2CzoerSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attack Model**"
      ],
      "metadata": {
        "id": "OxtFdbt8ec8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert the attack model dataset to tensors\n",
        "attack_model_dataset = torch.tensor(attack_model_dataset, dtype=torch.float32)\n",
        "X = attack_model_dataset[:, :-1]\n",
        "y = attack_model_dataset[:, -1]\n",
        "print(\"Shape of X:\", X.shape)\n",
        "print(\"Shape of X:\", y.shape)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use long tensor for classification\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=80, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=80, shuffle=False)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oMv2fNveepW",
        "outputId": "1dffbee4-b91f-445c-ae8c-0db58c7e69f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X: torch.Size([50000, 200])\n",
            "Shape of X: torch.Size([50000])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-09ad8192b606>:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_train_tensor = torch.tensor(X_train)\n",
            "<ipython-input-8-09ad8192b606>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_test_tensor = torch.tensor(X_test)\n",
            "<ipython-input-8-09ad8192b606>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train_tensor = torch.tensor(y_train, dtype=torch.float32)  # Use long tensor for classification\n",
            "<ipython-input-8-09ad8192b606>:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the attack model\n",
        "class AttackModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(AttackModel, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "4oQWmsEUefZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "attack_model = AttackModel(input_size, hidden_size, output_size)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(attack_model.parameters(), lr=0.001, weight_decay=1e-4)\n"
      ],
      "metadata": {
        "id": "1kVfFRtpehMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the attack model\n",
        "num_epochs = 50\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "attack_model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    attack_model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = attack_model(inputs)\n",
        "        loss = criterion(outputs.squeeze(), labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}\")"
      ],
      "metadata": {
        "id": "ko2HAvhzeiTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the attack model\n",
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, labels in test_loader:\n",
        "        tensors, labels = tensors.to(device), labels.to(device)\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "       # print(predicted)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "id": "DCFnJ90p7jQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the attack model\n",
        "torch.save(attack_model.state_dict(), '/content/drive/MyDrive/AMLM/pickle/attack_model.pth')\n"
      ],
      "metadata": {
        "id": "OHyUaKRW7nMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# attack_model= torch.load(\"/content/drive/MyDrive/AMLM/pickle/attack_model.pth\", map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "99JxsLK27p52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# files.download('/content/drive/MyDrive/AMLM/pickle/attack_model.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RH-u9Smg7rh7",
        "outputId": "77128056-e088-4b2d-895d-e9f02e179a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3d39f91e-96f4-4606-b0d2-25be49e4ffb0\", \"attack_model.pth\", 53880)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the target model and eval.p  Getting the Confidence Score and using it to evaluate the attack model**"
      ],
      "metadata": {
        "id": "mn4qD5UV8cOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "MODEL_PATH = '/content/drive/MyDrive/AMLM/models/resnet34_tinyimagenet.pth'\n",
        "# Change the MODEL_PATH to your local model path\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_classes = 200  # Change num_classes to 200 for the Tiny ImageNet dataset\n",
        "target_model = models.resnet34(num_classes=num_classes).to(device)\n",
        "\n",
        "# Load the state dictionary\n",
        "state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "target_model.load_state_dict(state_dict['net'])\n",
        "\n",
        "# Test accuracy\n",
        "acc = state_dict['acc']\n",
        "# Training epoch (start from 0)\n",
        "epoch = state_dict['epoch']\n",
        "\n",
        "print(f'Test Accuracy: {acc}')\n",
        "print(f'Training Epoch: {epoch}')\n"
      ],
      "metadata": {
        "id": "OM0swnzn8X4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/AMLM/pickle/tinyimagenet/resnet34/eval.p'\n",
        "# Change the DATA_PATH to your local pickle file path\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    eval_dataset = pickle.load(f)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    eval_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label, membership) in enumerate(dataloader):\n",
        "    img = img.to(device)"
      ],
      "metadata": {
        "id": "ecPxLi_g9SB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "Msied_gv9a1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_scores = []\n",
        "target_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for img, label, membership in dataloader:\n",
        "        img = img.to(device)\n",
        "        labels = label.to(device)\n",
        "        outputs = target_model(img)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        for i in range(len(img)):\n",
        "            confidence_scores.append(probabilities[i].tolist() + [membership[i]])\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total_predictions += labels.size(0)\n",
        "            correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    print(\"Accuracy:\",accuracy)\n"
      ],
      "metadata": {
        "id": "AVt3zP7v9cP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confidence_scores[0])"
      ],
      "metadata": {
        "id": "5qcKpqky9emZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetConf(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx][:-1]\n",
        "        label = self.data[idx][-1].item()\n",
        "        return torch.tensor(tensor), label"
      ],
      "metadata": {
        "id": "ccQk1rMs9eZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confidence_file_path = '/content/drive/MyDrive/AMLM/pickle/confidence_score.pkl'\n",
        "with open(confidence_file_path, 'wb') as f:\n",
        "    pickle.dump(confidence_scores, f)"
      ],
      "metadata": {
        "id": "VmAbXDQF9i7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/AMLM/pickle/confidence_score.pkl', 'rb') as f:\n",
        "  confidence_scores = pickle.load(f)"
      ],
      "metadata": {
        "id": "U6HoA3gW90Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(confidence_scores[0])"
      ],
      "metadata": {
        "id": "rZReIsM993C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conf_Score=CustomDatasetConf(confidence_scores)"
      ],
      "metadata": {
        "id": "zqitz45R96yt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accessing the dataset\n",
        "example_confidence_scores, example_membership = conf_Score[0]\n",
        "print(\"Example confidence scores:\", example_confidence_scores)\n",
        "print(\"Example membership:\", example_membership)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A1WCdR398lW",
        "outputId": "3d3c180e-1054-4c7f-a7c2-5b1b43d342dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example confidence scores: tensor([4.2025e-05, 2.2021e-05, 1.3912e-06, 4.3135e-06, 3.3721e-06, 7.8349e-05,\n",
            "        1.2336e-06, 1.5515e-05, 1.1036e-05, 1.9237e-05, 1.6901e-06, 5.3807e-05,\n",
            "        1.4707e-05, 1.5372e-05, 9.9986e-06, 2.3132e-06, 1.2362e-05, 1.5740e-05,\n",
            "        7.0877e-06, 2.8466e-06, 4.7801e-05, 7.5775e-06, 7.1177e-06, 5.7059e-06,\n",
            "        9.9619e-01, 5.0227e-05, 4.4501e-05, 3.3764e-05, 4.8981e-05, 5.1508e-05,\n",
            "        1.5150e-05, 9.8695e-06, 8.7276e-06, 2.0891e-05, 1.6575e-05, 1.8752e-06,\n",
            "        1.0862e-05, 2.3975e-06, 3.2469e-05, 2.5393e-06, 3.4819e-06, 8.5344e-06,\n",
            "        2.1251e-04, 1.9539e-06, 3.0751e-06, 1.4463e-05, 1.5324e-05, 6.2817e-05,\n",
            "        2.2666e-06, 9.4969e-06, 4.1931e-06, 1.9700e-05, 9.5376e-05, 6.7270e-06,\n",
            "        4.5894e-06, 3.7776e-06, 2.8701e-05, 4.5245e-06, 3.2387e-05, 1.7031e-05,\n",
            "        5.1241e-06, 1.4108e-06, 4.6627e-05, 3.4520e-06, 5.3858e-06, 1.9850e-06,\n",
            "        6.2891e-06, 6.3219e-06, 6.8475e-05, 1.4745e-05, 2.3718e-06, 3.5590e-06,\n",
            "        5.7750e-06, 4.0204e-05, 9.7622e-06, 4.8279e-06, 7.9171e-06, 1.3587e-05,\n",
            "        1.4883e-05, 2.0875e-05, 4.5324e-06, 2.9034e-06, 3.5293e-06, 2.7786e-05,\n",
            "        6.1881e-05, 1.1347e-05, 8.2020e-06, 3.9816e-06, 2.5304e-05, 7.9383e-06,\n",
            "        1.3605e-04, 1.7233e-05, 6.0641e-06, 5.3762e-06, 6.4554e-06, 9.3132e-06,\n",
            "        2.7352e-06, 3.9874e-06, 1.0080e-05, 2.7605e-05, 3.5028e-06, 4.4416e-06,\n",
            "        7.7282e-06, 6.7628e-06, 2.6523e-06, 4.4182e-06, 1.1560e-05, 4.4131e-06,\n",
            "        2.5112e-06, 7.1816e-05, 2.0201e-05, 3.6044e-06, 1.4469e-05, 3.1449e-06,\n",
            "        3.3494e-05, 2.1895e-06, 7.5849e-06, 1.4367e-05, 5.1572e-06, 5.6817e-06,\n",
            "        2.1436e-04, 2.6108e-06, 2.8371e-06, 2.7991e-05, 4.9808e-06, 1.2659e-05,\n",
            "        3.1804e-05, 2.4791e-06, 2.7497e-06, 2.0867e-05, 2.4221e-05, 4.1171e-05,\n",
            "        1.8159e-05, 1.8287e-06, 1.3464e-05, 1.4392e-05, 2.5597e-05, 1.8023e-05,\n",
            "        5.5056e-06, 4.4476e-06, 2.4530e-06, 1.7938e-05, 2.2007e-05, 8.2267e-05,\n",
            "        9.9483e-05, 4.4111e-06, 3.0611e-06, 4.0352e-06, 1.2270e-05, 1.1929e-04,\n",
            "        3.0117e-05, 3.2102e-06, 7.2985e-06, 4.6780e-06, 1.7165e-05, 1.7691e-05,\n",
            "        2.9754e-05, 1.1246e-04, 1.5812e-05, 3.7047e-05, 1.3292e-05, 1.5582e-05,\n",
            "        4.0991e-06, 3.4026e-05, 1.0513e-05, 2.5486e-06, 2.3383e-06, 1.3772e-05,\n",
            "        6.9884e-06, 2.5924e-06, 9.1748e-06, 9.9426e-06, 3.1928e-06, 2.9099e-06,\n",
            "        1.4188e-05, 5.6667e-06, 7.6557e-06, 1.4474e-05, 6.0812e-06, 6.9035e-06,\n",
            "        6.2623e-06, 3.0163e-05, 8.4287e-06, 8.9687e-06, 2.2043e-05, 1.9881e-05,\n",
            "        5.0225e-05, 3.9876e-06, 3.3773e-06, 8.5624e-05, 3.0552e-06, 1.1080e-05,\n",
            "        5.0229e-06, 2.5699e-06, 1.9974e-06, 3.9671e-06, 6.7542e-06, 2.3372e-06,\n",
            "        1.4282e-05, 5.6197e-06])\n",
            "Example membership: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(conf_Score))"
      ],
      "metadata": {
        "id": "hhrA7Xfg9_Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataLoader for the confidence scores\n",
        "confidence_scores_loader = DataLoader(conf_Score, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "aNgC3PAS-Ake"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(confidence_scores))"
      ],
      "metadata": {
        "id": "Sf9qInRc-B3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the attack model using the confidence score generated by the target model and eval.p\n",
        "attack_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for tensors, label in confidence_scores_loader:\n",
        "        tensors, label = tensors.to(device), label.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += tensors.size(0)\n",
        "        correct += (predicted==label).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EShY61qR-DZu",
        "outputId": "9eb9a419-8b9b-47e9-ec73-b428be72fd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 93.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the attack model\n",
        "attack_model.eval()\n",
        "final_results = []\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for tensors, label in confidence_scores_loader:\n",
        "        tensors, label = tensors.to(device), label.to(device).float()\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        total += tensors.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "        final_results.extend(predicted.cpu().numpy().tolist())\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total}%\")\n",
        "\n",
        "print(\"First 10 predicted results:\", final_results[:500])\n"
      ],
      "metadata": {
        "id": "sKMFi-TiMK3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT"
      ],
      "metadata": {
        "id": "9oeKh14JvugQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import torch\n",
        "\n",
        "DATA_PATH = '/content/drive/MyDrive/AMLM/pickle/tinyimagenet/resnet34/test.p'\n",
        "# Change the DATA_PATH to your local pickle file path\n",
        "\n",
        "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    testp_dataset = pickle.load(f)\n",
        "\n",
        "sample = next(iter(testp_dataset))\n",
        "print(f'Sample structure: {sample}')\n",
        "testp_dataloader = torch.utils.data.DataLoader(\n",
        "    testp_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "for batch_idx, (img, label) in enumerate(testp_dataloader):\n",
        "    img = img.to(device)"
      ],
      "metadata": {
        "id": "r3_061SMsiUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuhXREPKfWRB"
      },
      "outputs": [],
      "source": [
        "test_confidence_scores = []\n",
        "target_model.eval()\n",
        "with torch.no_grad():\n",
        "    for img,label in testp_dataloader:\n",
        "        img = img.to(device)\n",
        "        outputs = target_model(img)\n",
        "       # print(outputs.shape)\n",
        "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        for i in range(len(img)):\n",
        "          test_confidence_scores.append(probabilities[i].tolist())\n",
        "print(test_confidence_scores[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34mcjbA3qt2V"
      },
      "outputs": [],
      "source": [
        "print(len(test_confidence_scores[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XVNyT2xrGe9"
      },
      "outputs": [],
      "source": [
        "class CustomDatasetConft(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor = self.data[idx]\n",
        "\n",
        "        return torch.tensor(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvOhzKQ9qT2E"
      },
      "outputs": [],
      "source": [
        "test_conf_score=CustomDatasetConft(test_confidence_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t0AwTexnsUT3"
      },
      "outputs": [],
      "source": [
        "print(test_conf_score[0])\n",
        "print(len(test_conf_score[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jxXRB0Fr2kR"
      },
      "outputs": [],
      "source": [
        "# Evaluating the attack model using test.p\n",
        "attack_model.eval()\n",
        "Final_result=[]\n",
        "with torch.no_grad():\n",
        "    for tensors in test_conf_score:\n",
        "        tensors = tensors.to(device)\n",
        "        outputs = attack_model(tensors).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        Final_result.append(predicted.item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idU8YQPT1PmW"
      },
      "outputs": [],
      "source": [
        "predicted = np.array(Final_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3fUSuW91inw"
      },
      "outputs": [],
      "source": [
        "print(predicted[:200])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD13qoxP1kbE"
      },
      "outputs": [],
      "source": [
        "np.save('task2_resnet34_tinyimagenet.npy', predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EjEXtbad2cMo",
        "outputId": "cc54de5d-87bf-4557-bf15-56fe04c9777c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_481c10be-b075-4c4a-9070-245bae0e0dda\", \"task2_resnet34_tinyimagenet.npy\", 160128)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('task2_resnet34_tinyimagenet.npy')\n"
      ]
    }
  ]
}